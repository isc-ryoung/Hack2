# Data Model: Instance - IRIS Operations Agent

**Feature**: [spec.md](spec.md) | **Plan**: [plan.md](plan.md) | **Research**: [research.md](research.md)  
**Created**: 2026-02-06  
**Purpose**: Define all data entities, relationships, and validation rules

## Overview

The Instance system uses **Pydantic v2 models** for all data structures, providing:
- Type safety and validation
- JSON serialization/deserialization
- OpenAI structured output compatibility
- Self-documenting schemas

All models are defined in `src/models/` and used by agents for structured input/output.

---

## Core Entities

### 1. ErrorMessage

**Purpose**: Represents a simulated IRIS error message in messages.log format

**Location**: `src/models/error_message.py`

**Model Definition**:
```python
from pydantic import BaseModel, Field, field_validator
from datetime import datetime
from typing import Literal

class ErrorMessage(BaseModel):
    """
    Represents an IRIS messages.log error entry.
    
    Example format:
    11/14/25-09:45:57:762 (50803) 2 [Generic.Event] Kerberos authentication unavailable
    """
    timestamp: str = Field(
        description="Timestamp in MM/DD/YY-HH:MM:SS:mmm format",
        pattern=r"^\d{2}/\d{2}/\d{2}-\d{2}:\d{2}:\d{2}:\d{3}$"
    )
    process_id: int = Field(
        description="IRIS process ID",
        ge=1,
        le=999999
    )
    severity: Literal[0, 1, 2, 3] = Field(
        description="Severity level: 0=info, 1=warning, 2=error, 3=fatal"
    )
    category: str = Field(
        description="Error category tag in [Category.Subcategory] format",
        pattern=r"^\[[\w\.]+\]$"
    )
    message_text: str = Field(
        description="Human-readable error description",
        min_length=10,
        max_length=500
    )
    
    @field_validator('timestamp')
    @classmethod
    def validate_timestamp_format(cls, v: str) -> str:
        """Ensure timestamp matches IRIS format"""
        try:
            # Validate format can be parsed
            parts = v.split('-')
            date_part, time_part = parts[0], parts[1]
            datetime.strptime(date_part, "%m/%d/%y")
            # Time validation
            h, m, s = time_part.split(':')
            assert 0 <= int(h) <= 23 and 0 <= int(m) <= 59 and 0 <= int(s) <= 59
            return v
        except Exception:
            raise ValueError(f"Invalid timestamp format: {v}")
    
    def to_log_format(self) -> str:
        """Convert to IRIS messages.log line format"""
        return f"{self.timestamp} ({self.process_id}) {self.severity} {self.category} {self.message_text}"
    
    class Config:
        json_schema_extra = {
            "examples": [{
                "timestamp": "02/06/26-14:30:45:123",
                "process_id": 12345,
                "severity": 2,
                "category": "[Utility.Event]",
                "message_text": "LMF Error: No valid license key. No valid local file found."
            }]
        }
```

**Relationships**:
- Generated by: `ErrorGeneratorAgent`
- Consumed by: `MessageSenderService` (external output)
- Stored in: Message queue (JSON format)

**Validation Rules**:
- `timestamp`: Must match IRIS format, valid date/time values
- `process_id`: Positive integer, realistic range
- `severity`: Must be 0, 1, 2, or 3
- `category`: Must be bracketed tag format
- `message_text`: Reasonable length (10-500 chars)

---

### 2. RemediationCommand

**Purpose**: Represents a remediation action request from external system

**Location**: `src/models/remediation_command.py`

**Model Definition**:
```python
from pydantic import BaseModel, Field
from typing import Literal, Dict, Any, Optional
from uuid import UUID, uuid4

class RemediationCommand(BaseModel):
    """
    Remediation command received from external system in JSON format.
    
    Example:
    {
        "command_id": "550e8400-e29b-41d4-a716-446655440000",
        "action_type": "config_change",
        "target": "iris.cpf",
        "parameters": {
            "section": "Startup",
            "key": "globals",
            "value": "20000"
        },
        "priority": "high"
    }
    """
    command_id: UUID = Field(
        default_factory=uuid4,
        description="Unique command identifier"
    )
    action_type: Literal["config_change", "os_reconfig", "restart"] = Field(
        description="Type of remediation action"
    )
    target: str = Field(
        description="Target resource (e.g., 'iris.cpf', 'hugepages', 'instance')",
        min_length=1,
        max_length=100
    )
    parameters: Dict[str, Any] = Field(
        description="Action-specific parameters"
    )
    priority: Literal["low", "medium", "high", "critical"] = Field(
        default="medium",
        description="Execution priority"
    )
    requester: Optional[str] = Field(
        default=None,
        description="Identity of requesting system"
    )
    
    @field_validator('parameters')
    @classmethod
    def validate_parameters_by_action(cls, v: Dict, info) -> Dict:
        """Validate parameters match action_type requirements"""
        action_type = info.data.get('action_type')
        
        if action_type == "config_change":
            required = {"section", "key", "value"}
            if not required.issubset(v.keys()):
                raise ValueError(f"config_change requires: {required}")
        
        elif action_type == "os_reconfig":
            required = {"resource_type", "target_value"}
            if not required.issubset(v.keys()):
                raise ValueError(f"os_reconfig requires: {required}")
        
        elif action_type == "restart":
            if "mode" in v and v["mode"] not in ["graceful", "forced"]:
                raise ValueError("restart mode must be 'graceful' or 'forced'")
        
        return v
    
    class Config:
        json_schema_extra = {
            "examples": [
                {
                    "command_id": "550e8400-e29b-41d4-a716-446655440000",
                    "action_type": "config_change",
                    "target": "iris.cpf",
                    "parameters": {
                        "section": "Startup",
                        "key": "globals",
                        "value": "20000"
                    },
                    "priority": "high",
                    "requester": "monitoring-system"
                },
                {
                    "command_id": "550e8400-e29b-41d4-a716-446655440001",
                    "action_type": "os_reconfig",
                    "target": "hugepages",
                    "parameters": {
                        "resource_type": "memory",
                        "target_value": 16384
                    },
                    "priority": "medium"
                },
                {
                    "command_id": "550e8400-e29b-41d4-a716-446655440002",
                    "action_type": "restart",
                    "target": "instance",
                    "parameters": {
                        "mode": "graceful",
                        "timeout_seconds": 60
                    },
                    "priority": "high"
                }
            ]
        }
```

**Relationships**:
- Received by: `CommandReceiverService`
- Routed by: `OrchestratorAgent`
- Executed by: `ConfigAgent`, `OSAgent`, or `RestartAgent`

**Validation Rules**:
- `action_type`: Must be one of the three supported types
- `parameters`: Must contain required fields for action type
- `priority`: Affects execution order
- `command_id`: UUID for tracking and idempotency

---

### 3. Agent Response Models

**Purpose**: Structured outputs from each agent type

**Location**: `src/models/agent_responses.py`

#### 3.1 OrchestratorResponse

```python
from pydantic import BaseModel, Field
from typing import List, Optional

class OrchestratorResponse(BaseModel):
    """Response from OrchestratorAgent after analyzing command"""
    agent_type: Literal["config", "os", "restart", "none"] = Field(
        description="Which agent should handle this command"
    )
    command_str: str = Field(
        description="Serialized command to pass to selected agent"
    )
    rationale: str = Field(
        description="Explanation of agent selection decision"
    )
    requires_validation: bool = Field(
        description="Whether pre-execution validation needed"
    )
    estimated_risk: Literal["low", "medium", "high"] = Field(
        description="Risk assessment for operation"
    )
    
    class Config:
        json_schema_extra = {
            "examples": [{
                "agent_type": "config",
                "command_str": "{\"section\": \"Startup\", \"key\": \"globals\", \"value\": \"20000\"}",
                "rationale": "Command modifies IRIS CPF configuration parameter 'globals'",
                "requires_validation": True,
                "estimated_risk": "medium"
            }]
        }
```

#### 3.2 ConfigAgentResponse

```python
class ConfigAgentResponse(BaseModel):
    """Response from ConfigAgent after configuration change"""
    success: bool = Field(description="Whether operation succeeded")
    section: str = Field(description="CPF section modified")
    key: str = Field(description="Configuration key modified")
    old_value: Optional[str] = Field(description="Previous value")
    new_value: str = Field(description="New value")
    requires_restart: bool = Field(description="Whether IRIS restart required")
    backup_path: Optional[str] = Field(description="Path to CPF backup file")
    error_message: Optional[str] = Field(default=None, description="Error details if failed")
    
    class Config:
        json_schema_extra = {
            "examples": [{
                "success": True,
                "section": "Startup",
                "key": "globals",
                "old_value": "10000",
                "new_value": "20000",
                "requires_restart": True,
                "backup_path": "/usr/local/IRIS/iris.cpf.backup.20260206",
                "error_message": None
            }]
        }
```

#### 3.3 OSAgentResponse

```python
class OSAgentResponse(BaseModel):
    """Response from OSAgent after OS reconfiguration"""
    success: bool = Field(description="Whether operation succeeded")
    resource_type: Literal["memory", "cpu"] = Field(description="Resource type modified")
    operation: str = Field(description="Specific operation performed")
    old_value: Optional[str] = Field(description="Previous setting")
    new_value: str = Field(description="New setting")
    validation_passed: bool = Field(description="Whether post-change validation passed")
    rollback_available: bool = Field(description="Whether rollback is possible")
    error_message: Optional[str] = Field(default=None, description="Error details if failed")
    
    class Config:
        json_schema_extra = {
            "examples": [{
                "success": True,
                "resource_type": "memory",
                "operation": "configure_huge_pages",
                "old_value": "8192 pages",
                "new_value": "16384 pages",
                "validation_passed": True,
                "rollback_available": True,
                "error_message": None
            }]
        }
```

#### 3.4 RestartAgentResponse

```python
class RestartAgentResponse(BaseModel):
    """Response from RestartAgent after instance restart"""
    success: bool = Field(description="Whether restart succeeded")
    mode: Literal["graceful", "forced"] = Field(description="Restart mode used")
    shutdown_duration_seconds: float = Field(description="Time taken for shutdown")
    startup_duration_seconds: float = Field(description="Time taken for startup")
    databases_mounted: int = Field(description="Number of databases mounted")
    validation_passed: bool = Field(description="Whether post-startup validation passed")
    error_message: Optional[str] = Field(default=None, description="Error details if failed")
    
    class Config:
        json_schema_extra = {
            "examples": [{
                "success": True,
                "mode": "graceful",
                "shutdown_duration_seconds": 45.3,
                "startup_duration_seconds": 12.7,
                "databases_mounted": 7,
                "validation_passed": True,
                "error_message": None
            }]
        }
```

---

### 4. ExecutionContext

**Purpose**: Tracks runtime state across agent executions

**Location**: `src/models/execution_context.py`

**Model Definition**:
```python
from pydantic import BaseModel, Field
from typing import Dict, List, Optional
from uuid import UUID
from datetime import datetime

class ExecutionContext(BaseModel):
    """Runtime execution state for remediation workflow"""
    trace_id: UUID = Field(description="Unique trace ID for correlation")
    command_id: UUID = Field(description="Command being executed")
    started_at: datetime = Field(default_factory=datetime.now)
    current_agent: Optional[str] = Field(default=None, description="Currently executing agent")
    completed_agents: List[str] = Field(default_factory=list, description="Agents that have completed")
    agent_results: Dict[str, str] = Field(default_factory=dict, description="Results from each agent")
    total_tokens_used: int = Field(default=0, description="Total tokens consumed")
    total_cost_usd: float = Field(default=0.0, description="Total cost incurred")
    errors: List[str] = Field(default_factory=list, description="Errors encountered")
    
    def add_agent_result(self, agent_name: str, result_json: str, tokens: int, cost: float):
        """Record agent execution result"""
        self.completed_agents.append(agent_name)
        self.agent_results[agent_name] = result_json
        self.total_tokens_used += tokens
        self.total_cost_usd += cost
    
    def add_error(self, error_message: str):
        """Record error during execution"""
        self.errors.append(error_message)
    
    @property
    def has_errors(self) -> bool:
        """Check if any errors occurred"""
        return len(self.errors) > 0
    
    @property
    def duration_seconds(self) -> float:
        """Calculate total execution duration"""
        return (datetime.now() - self.started_at).total_seconds()
```

**Relationships**:
- Created by: Initial command reception
- Updated by: All agents during execution
- Logged by: Observability layer
- Used for: Tracing, cost tracking, error handling

---

## Supporting Models

### 5. ErrorGenerationRequest

**Purpose**: Input to ErrorGeneratorAgent

**Location**: `src/models/error_message.py`

```python
class ErrorGenerationRequest(BaseModel):
    """Request for generating IRIS error message"""
    error_category: Literal["config", "license", "os_resource", "journal", "database"] = Field(
        description="Category of error to generate"
    )
    severity: Optional[Literal[0, 1, 2, 3]] = Field(
        default=None,
        description="Desired severity (if None, agent decides)"
    )
    context: Optional[str] = Field(
        default=None,
        description="Additional context for generation"
    )
```

### 6. ValidationResult

**Purpose**: Result of pre/post-condition validation

**Location**: `src/models/agent_responses.py`

```python
class ValidationResult(BaseModel):
    """Result of validation check"""
    passed: bool = Field(description="Whether validation passed")
    checks_performed: List[str] = Field(description="List of validation checks")
    failures: List[str] = Field(default_factory=list, description="Failed checks")
    warnings: List[str] = Field(default_factory=list, description="Warning conditions")
    can_proceed: bool = Field(description="Whether operation can proceed")
    
    @property
    def has_warnings(self) -> bool:
        return len(self.warnings) > 0
```

---

## Entity Relationships

```
                                    ┌─────────────────┐
                                    │External System  │
                                    └────────┬────────┘
                                             │
                    ┌────────────────────────┼────────────────────────┐
                    │                        │                        │
                    ▼                        ▼                        ▼
            ┌──────────────┐        ┌───────────────┐       ┌──────────────┐
            │ErrorMessage  │        │Remediation    │       │Message       │
            │              │        │Command        │       │Sender        │
            └──────┬───────┘        └───────┬───────┘       └──────────────┘
                   │                        │
                   │                        ▼
                   │                ┌──────────────────┐
                   │                │Orchestrator      │
                   │                │Response          │
                   │                └────────┬─────────┘
                   │                         │
                   │         ┌───────────────┼───────────────┐
                   │         │               │               │
                   │         ▼               ▼               ▼
                   │  ┌────────────┐  ┌───────────┐  ┌──────────────┐
                   │  │Config      │  │OS         │  │Restart       │
                   │  │Agent       │  │Agent      │  │Agent         │
                   │  │Response    │  │Response   │  │Response      │
                   │  └────────────┘  └───────────┘  └──────────────┘
                   │         │               │               │
                   │         └───────────────┴───────────────┘
                   │                         │
                   │                         ▼
                   │                 ┌──────────────────┐
                   └─────────────────│Execution         │
                                     │Context           │
                                     └──────────────────┘
```

---

## Validation Strategy

All models use Pydantic's validation:

1. **Type Validation**: Automatic via type hints
2. **Field Validation**: Using `Field()` constraints (min/max, pattern, etc.)
3. **Model Validation**: Using `@field_validator` for complex rules
4. **Cross-field Validation**: Using `@model_validator` when needed

**Example Validation Flow**:
```python
# 1. Receive JSON string
command_json = '{"action_type": "config_change", ...}'

# 2. Parse with Pydantic (automatic validation)
try:
    command = RemediationCommand.model_validate_json(command_json)
except ValidationError as e:
    # Handle validation errors
    log.error("command_validation_failed", errors=e.errors())
    return error_response

# 3. Use validated data
orchestrator_response = orchestrator_agent.execute(command)
```

---

## Schema Generation

All models auto-generate JSON schemas for contracts:

```python
# Generate JSON schema for RemediationCommand
schema = RemediationCommand.model_json_schema()

# Save to contracts directory
with open("specs/001-iris-ops-agent/contracts/remediation_command_schema.json", "w") as f:
    json.dump(schema, f, indent=2)
```

---

## Next Steps

1. ✅ Generate JSON schemas in contracts/ directory
2. ✅ Create quickstart.md with model usage examples
3. Implement models in src/models/
4. Write unit tests for model validation
5. Begin agent implementation using these models
